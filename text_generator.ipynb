{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNM4NsNEzGkRScGcrSnltDn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keshvi-srivastava/star-wars-dialogue-generation/blob/main/text_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tkdj-ApD63y"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3HRMq0zER9o"
      },
      "source": [
        "path_to_file = '/content/sample_data/script_data.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVvcY4qQECP2",
        "outputId": "e184681a-c5df-4d55-ca79-c15c19d7a66d"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 179673 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "B214pZDREhkQ",
        "outputId": "8ee78f50-0415-4f24-b057-efab2e79036f"
      },
      "source": [
        "\n",
        "# Taking a look at the text\n",
        "text[:300]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"threepio: Did you hear that?  They've shut down the main reactor.  We'll be destroyed for sure.  This is madness!\\nthreepio: We're doomed!\\nthreepio: There'll be no escape for the Princess this time.\\nthreepio: What's that?\\nthreepio: I should have known better than to trust the logic of a half-sized th\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sksxr4YaG7x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Rq-gqpaHIF"
      },
      "source": [
        "Python for NLP Deep Learning text gen with keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY3BdhqlWqTV"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WReZyjDqWrQn"
      },
      "source": [
        "text = preprocess_text(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA9W83aPEnp8",
        "outputId": "5e67213d-bd12-4772-9f27-b80fcea817d0"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35bZScjNXuXz",
        "outputId": "d07cfdba-8f11-4782-a02d-7c1c73763230"
      },
      "source": [
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtqTeB82Y_yH",
        "outputId": "9da764c1-b232-465a-f312-a8e212c0df43"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoWkkvLLX1CP",
        "outputId": "9a4d547a-90fb-444a-9576-110b0494c6f0"
      },
      "source": [
        "text_words = (word_tokenize(text))\n",
        "n_words = len(text_words)\n",
        "unique_words = len(set(text_words))\n",
        "\n",
        "print('Total Words: %d' % n_words)\n",
        "print('Unique Words: %d' % unique_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Words: 31032\n",
            "Unique Words: 3503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QC0myVxZHb1"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=3437)\n",
        "tokenizer.fit_on_texts(text_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUnlud0_ZL1k"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "word_2_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zet66mEFZTfV"
      },
      "source": [
        "input_sequence = []\n",
        "output_words = []\n",
        "input_seq_length = 100\n",
        "\n",
        "for i in range(0, n_words - input_seq_length , 1):\n",
        "    in_seq = text_words[i:i + input_seq_length]\n",
        "    out_seq = text_words[i + input_seq_length]\n",
        "    input_sequence.append([word_2_index[word] for word in in_seq])\n",
        "    output_words.append(word_2_index[out_seq])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBGe7hD8Zj3u"
      },
      "source": [
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from random import randint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQK_y4_nZXDY"
      },
      "source": [
        "X = np.reshape(input_sequence, (len(input_sequence), input_seq_length, 1))\n",
        "X = X / float(vocab_size)\n",
        "\n",
        "y = to_categorical(output_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KYK7TcTZXJ6",
        "outputId": "4b8f9bea-bb84-45e7-d1a9-6d78008acbf3"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(800, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(800, return_sequences=True))\n",
        "model.add(LSTM(800))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 800)          2566400   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 800)          5123200   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 800)               5123200   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3504)              2806704   \n",
            "=================================================================\n",
            "Total params: 15,619,504\n",
            "Trainable params: 15,619,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cExLO_moZXOA",
        "outputId": "38137252-71b5-465b-a808-bb72ef54c895"
      },
      "source": [
        "model.fit(X, y, batch_size=64, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "484/484 [==============================] - 87s 112ms/step - loss: 6.5413\n",
            "Epoch 2/10\n",
            "484/484 [==============================] - 55s 113ms/step - loss: 6.1911\n",
            "Epoch 3/10\n",
            "484/484 [==============================] - 55s 113ms/step - loss: 6.1741\n",
            "Epoch 4/10\n",
            "484/484 [==============================] - 55s 113ms/step - loss: 6.1726\n",
            "Epoch 5/10\n",
            "484/484 [==============================] - 55s 113ms/step - loss: 6.1815\n",
            "Epoch 6/10\n",
            "484/484 [==============================] - 55s 113ms/step - loss: 6.1708\n",
            "Epoch 7/10\n",
            "484/484 [==============================] - 55s 113ms/step - loss: 6.1763\n",
            "Epoch 8/10\n",
            "484/484 [==============================] - 55s 113ms/step - loss: 6.1699\n",
            "Epoch 9/10\n",
            "484/484 [==============================] - 55s 113ms/step - loss: 6.1594\n",
            "Epoch 10/10\n",
            "484/484 [==============================] - 55s 114ms/step - loss: 6.1718\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbef80881d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykCFd06gZrBx",
        "outputId": "59c5df2a-9a30-4f2c-e07f-9f1d2101b85c"
      },
      "source": [
        "random_seq_index = np.random.randint(0, len(input_sequence)-1)\n",
        "random_seq = input_sequence[random_seq_index]\n",
        "\n",
        "index_2_word = dict(map(reversed, word_2_index.items()))\n",
        "\n",
        "word_sequence = [index_2_word[value] for value in random_seq]\n",
        "\n",
        "print(' '.join(word_sequence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the hyperdrive motivator has been damaged it impossible to go to light speed han we re in trouble han horizontal boosters han alluvial dampers well that not it han bring me the hydrospanners han don know how we re going to get out of this one han oww chewie han that was no laser blast something hit us leia han get up here han come on chewie leia asteroids han oh no chewie set two seven one leia what are you doing you re not actually going into an asteroid field han they be crazy to follow us wouldn they\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioGDw17nZrFZ"
      },
      "source": [
        "for i in range(100):\n",
        "    int_sample = np.reshape(random_seq, (1, len(random_seq), 1))\n",
        "    int_sample = int_sample / float(vocab_size)\n",
        "\n",
        "    predicted_word_index = model.predict(int_sample, verbose=0)\n",
        "\n",
        "    predicted_word_id = np.argmax(predicted_word_index)\n",
        "    seq_in = [index_2_word[index] for index in random_seq]\n",
        "\n",
        "    word_sequence.append(index_2_word[ predicted_word_id])\n",
        "\n",
        "    random_seq.append(predicted_word_id)\n",
        "    random_seq = random_seq[1:len(random_seq)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VR1yoD-ZrJk",
        "outputId": "9d825ee7-e0d2-4101-fbf0-ee02314209d8"
      },
      "source": [
        "final_output = \"\"\n",
        "for word in word_sequence:\n",
        "    final_output = final_output + \" \" + word\n",
        "\n",
        "print(final_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " the hyperdrive motivator has been damaged it impossible to go to light speed han we re in trouble han horizontal boosters han alluvial dampers well that not it han bring me the hydrospanners han don know how we re going to get out of this one han oww chewie han that was no laser blast something hit us leia han get up here han come on chewie leia asteroids han oh no chewie set two seven one leia what are you doing you re not actually going into an asteroid field han they be crazy to follow us wouldn they you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPsmkc3MfeOv"
      },
      "source": [
        "Change the hyper parameters, including the size and number of LSTM layers and number of epochs to see if you get better results.\n",
        "Try to remove the stop words like is, am, are from training set to generate words other than stop words in the test set (although this will depend on the type of application).\n",
        "Create a character-level text generation model that predicts the next N characters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl0hRhWpaATe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmfqyoDxaAnH"
      },
      "source": [
        "HP Text Generator example\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6S-D2ONEr2x",
        "outputId": "be0fc603-d107-4130-b88e-a2d268b8ce56"
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2index = {u:i for i, u in enumerate(vocab)}\n",
        "index2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2index[c] for c in text])\n",
        "\n",
        "print(text_as_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[63 51 61 ... 63  2  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "213dLtDnExhS",
        "outputId": "b7d4b40a-c23f-4fcb-aea8-7cc60dc76221"
      },
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "print ('{} -- characters mapped to int -- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'threepio: Did' -- characters mapped to int -- > [63 51 61 48 48 59 52 58 16  1 22 52 47]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daP63AOgE0uX",
        "outputId": "e433546f-999d-48b2-a4ad-65a234345047"
      },
      "source": [
        "\n",
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(index2char[i.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t\n",
            "h\n",
            "r\n",
            "e\n",
            "e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjTr_p-_E3Dp",
        "outputId": "fdfd189f-25e2-40e6-df16-a359574533cf"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(index2char[item.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"threepio: Did you hear that?  They've shut down the main reactor.  We'll be destroyed for sure.  This\"\n",
            "\" is madness!\\nthreepio: We're doomed!\\nthreepio: There'll be no escape for the Princess this time.\\nthre\"\n",
            "\"epio: What's that?\\nthreepio: I should have known better than to trust the logic of a half-sized therm\"\n",
            "'ocapsulary dehousing assister...\\nthreepio: Artoo! Artoo-Detoo, where are you?\\nthreepio: At last!  Whe'\n",
            "\"re have you been?\\nthreepio: They're heading in this direction. What are we going to do?  We'll be sen\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb4wGQqKE6ql"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn63xV-YE9gc",
        "outputId": "082c8c8c-13b3-4dd7-af7b-2e2317de3918"
      },
      "source": [
        "\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVrZD0gmE_0o",
        "outputId": "b23f0a57-9194-472b-e9be-4189d1f5dd07"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 300 #256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units1 = 512 #1024\n",
        "rnn_units2 = 256\n",
        "rnn_units=[rnn_units1, rnn_units2]\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvRzLNG4FCOd"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units1,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.GRU(rnn_units2,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKheD_O_FEVW"
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = vocab_size,\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lZnIT7ZFGJe",
        "outputId": "da5c80d4-c5aa-474f-c60f-91f410de96f4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 300)           22200     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 512)           1250304   \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (64, None, 256)           591360    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 74)            19018     \n",
            "=================================================================\n",
            "Total params: 1,882,882\n",
            "Trainable params: 1,882,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4PEgYIoFKbX"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8_BOZI0FNkn"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dafYqeYuFPjt"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4l1Y-SEFR1P",
        "outputId": "7bdae620-b70d-48c5-d677-d4152a6f4f23"
      },
      "source": [
        "EPOCHS=50\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "27/27 [==============================] - 48s 2s/step - loss: 3.8575 - accuracy: 0.1231\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 45s 2s/step - loss: 3.1474 - accuracy: 0.1827\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 2.7789 - accuracy: 0.2546\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 2.3850 - accuracy: 0.3393\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 2.1846 - accuracy: 0.3827\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 2.0512 - accuracy: 0.4145\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 1.9402 - accuracy: 0.4400\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 1.8477 - accuracy: 0.4626\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 1.7616 - accuracy: 0.4867\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 1.7022 - accuracy: 0.5029\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 1.6181 - accuracy: 0.5248\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 1.5738 - accuracy: 0.5374\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 1.5206 - accuracy: 0.5505\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 1.4715 - accuracy: 0.5639\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 1.4381 - accuracy: 0.5743\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 1.3946 - accuracy: 0.5848\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 1.3512 - accuracy: 0.5955\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 42s 2s/step - loss: 1.3240 - accuracy: 0.6038\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 42s 2s/step - loss: 1.2894 - accuracy: 0.6124\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 1.2572 - accuracy: 0.6227\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 42s 2s/step - loss: 1.2296 - accuracy: 0.6319\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 1.1976 - accuracy: 0.6387\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 1.1758 - accuracy: 0.6469\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 1.1391 - accuracy: 0.6580\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 42s 2s/step - loss: 1.1182 - accuracy: 0.6636\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 1.0980 - accuracy: 0.6706\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 42s 2s/step - loss: 1.0570 - accuracy: 0.6805\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 1.0341 - accuracy: 0.6902\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 1.0123 - accuracy: 0.6959\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.9878 - accuracy: 0.7044\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.9626 - accuracy: 0.7133\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.9342 - accuracy: 0.7219\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.9061 - accuracy: 0.7316\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.8719 - accuracy: 0.7426\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 42s 2s/step - loss: 0.8547 - accuracy: 0.7486\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.8256 - accuracy: 0.7581\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.7960 - accuracy: 0.7710\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.7723 - accuracy: 0.7781\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.7415 - accuracy: 0.7888\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.7184 - accuracy: 0.7995\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.6915 - accuracy: 0.8081\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.6632 - accuracy: 0.8185\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.6434 - accuracy: 0.8258\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.6147 - accuracy: 0.8348\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.5908 - accuracy: 0.8456\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.5689 - accuracy: 0.8519\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.5482 - accuracy: 0.8605\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.5233 - accuracy: 0.8691\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 44s 2s/step - loss: 0.5019 - accuracy: 0.8776\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 43s 2s/step - loss: 0.4888 - accuracy: 0.8819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxGrPgd8FWCa"
      },
      "source": [
        "latest_check= tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OMbHM_XNtuO"
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(latest_check)\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcWHSlCtNwJD",
        "outputId": "42ef0748-297a-401a-9307-71bdb997d4c5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 300)            22200     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (1, None, 512)            1250304   \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (1, None, 256)            591360    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 74)             19018     \n",
            "=================================================================\n",
            "Total params: 1,882,882\n",
            "Trainable params: 1,882,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_yzVuDPN0Or"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2index[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low results in more predictable text.\n",
        "  # Higher results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  scaling = 0.5 #1\n",
        "\n",
        "  # batch size == 1\n",
        "  \n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / scaling\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden stte\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(index2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3HR6Vh0OfiP",
        "outputId": "60d2b329-22f1-4233-abef-c58fa6ca55ac"
      },
      "source": [
        "print(generate_text(model, start_string=u\"yoda:\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yoda: Arrogant in a planets havedisappear.  What's he saying?\n",
            "threepio: Well, I should have known on the outskirts and bring usioned to the ship. I'm staying your bunderesting a dream.\n",
            "vader: I like two or three, but I'm not sure this is the father, isn't he?\n",
            "ben: (continuing) What's this asteroid field so that we meet on the Jedi the end of your: Artoo.\n",
            "vader: (subtitled) Chess the galaxy as fast assion. The Jedi Council is some rooking for.\n",
            "vader: Here we go.\n",
            "ben: I'm trying to stop! Whoa!\n",
            "vader: (Cont'd) I'm trying to take her. I don't understand. Stay on the Dook. I will do what you've done . . . what you were you all right?\n",
            "vader: It's not a ship.  I'm in it for the making . . .\n",
            "vader: I'm going to save Obi-Wan. I sense something rather way.\n",
            "threepio: We're doomed.\n",
            "threepio: I think I know what you're talking about his mining to go.\n",
            "vader: Yes, Anakin.\n",
            "vader: I don't know where they don't trust you.\n",
            "padme: Anakin, this is my droids are wanted of the Force, that incomplete will see me, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxsipByhTgJh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}